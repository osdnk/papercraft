
use ndarray::Array1;
use crate::arithmetic;
use crate::arithmetic::{add_matrices, parallel_dot_matrix_matrix, sample_random_mat, sample_random_vector, vector_element_product, add_vectors, parallel_dot_vector_matrix, parallel_dot_matrix_vector, reshape, tensor_identity_matrix_with_vector, get_g, zero_vector, tensor_identity_matrix_with_matrix, transpose, zero_mat, decompose_vector, sample_random_vector_subring, sample_random_mat_subring};
use crate::subroutines::crs::CRS;
use crate::helpers::println_with_timestamp;
use crate::custom_ring::r#static::{LOG_Q, MODULE_SIZE};
use crate::custom_ring::ring::{DPrimeRingElement, Ring};

/// Struct representing the output of the VDF (Verifiable Delay Function) computation
pub struct VDFOutputMat {
    /// The witness part of the output
    pub witness: Vec<DPrimeRingElement>,
    /// The final image/output generated by the VDF computation
    pub output_image: Vec<DPrimeRingElement>,
    /// Intermediate images generated at each repetition step
    pub intermediate_images: Vec<Vec<DPrimeRingElement>>,
}


/// Executes the VDF (Verifiable Delay Function)
///
/// # Arguments
///
/// * `y_a` - Initial vector.
/// * `a` - Matrix used in the dot product computations.
/// * `rep` - Number of repetitions.
/// * `time` - Number of iterations/time to run the VDF.
///
/// # Returns
///
/// A `VDFOutputMat` containing the final image, witness, and intermediate images.
pub fn execute_vdf(y_a: &Vec<DPrimeRingElement>, a: &Vec<Vec<DPrimeRingElement>>, rep: usize, time: usize) -> VDFOutputMat {
    let mut witness: Vec<Vec<DPrimeRingElement>> = Vec::with_capacity(time);
    let mut intermediate_images: Vec<Vec<DPrimeRingElement>> = Vec::with_capacity(rep);
    let mut rem = y_a.clone();

    // Decompose the initial vector's elements and flatten them
    // let decomposed: Vec<Vec<DPrimeRingElement>> = rem.iter().map(|r| r.g_decompose()).collect();/
    // TODO
    let decomposed = decompose_vector(&rem, 2, LOG_Q);

    let decompose_flattened: Vec<DPrimeRingElement> = decomposed.iter().flatten().cloned().collect();
    let mut decompose_flattened_arr = decompose_flattened.clone();
    witness.push(decompose_flattened);


    // Ensure time is compatible with the number of repetitions
    assert_eq!(time % rep, 0, "T is not compatible with the number of repetitions");

    let intermediate_image_modulus = time / rep;

    for i in 0..(time - 1) {
        // Collect intermediate images at specified intervals
        if i % intermediate_image_modulus == 0 && i != 0  {
            intermediate_images.push(rem);
        }
        // Compute the next remainder using parallel dot product and negation
        rem = parallel_dot_matrix_vector(a, &decompose_flattened_arr).iter().map(DPrimeRingElement::negative).collect();

        let decomposed = decompose_vector(&rem, 2, LOG_Q);
        // let decomposed: Vec<Vec<DPrimeRingElement>> = rem.iter().map(|r| r.g_decompose()).collect();
        let decompose_flattened: Vec<DPrimeRingElement> = decomposed.iter().flatten().cloned().collect();
        decompose_flattened_arr = decompose_flattened.clone();
        witness.push(decompose_flattened);
    }

    // Combine the witness vectors into a single vector
    let mut combined_witness = Vec::with_capacity(witness.len() * witness[0].len());
    for vec in witness {
        for element in vec {
            combined_witness.push(element);
        }
    }

    VDFOutputMat {
        output_image: parallel_dot_matrix_vector(a, &decompose_flattened_arr),
        witness: combined_witness,
        intermediate_images
    }
}



#[test]
fn test_vdf() {
    let time = 5;
    let a = sample_random_mat_subring(MODULE_SIZE, LOG_Q * MODULE_SIZE);
    let y_a = sample_random_vector_subring(MODULE_SIZE);
    use std::time::Instant;
    let now = Instant::now();
    let output = execute_vdf(&y_a, &a, 1, time);
    let elapsed = now.elapsed();
    println_with_timestamp!("Elapsed: {:.2?}", elapsed);

    // Reshape the witness
    let witness_reshaped = reshape(&output.witness.to_vec(), LOG_Q * MODULE_SIZE);
    // Generate the G matrix
    let G = tensor_identity_matrix_with_vector(&get_g(LOG_Q), MODULE_SIZE);
    assert_eq!(parallel_dot_matrix_vector(&G, &witness_reshaped[0]), y_a );

    // Validate intermediate steps
    for i in 1..(time - 1) {
        println!("KKK {:?}", i);
        assert_eq!(
            arithmetic::add(&parallel_dot_matrix_vector(&G, &witness_reshaped[i]),
                            &parallel_dot_matrix_vector(&a, &witness_reshaped[i - 1])),
            zero_vector(MODULE_SIZE)
        );
    }

    // Validate final output
    assert_eq!(parallel_dot_matrix_vector(&a, &witness_reshaped[time - 1]), output.output_image);
}

pub fn powers(ell: &DPrimeRingElement, dim: usize) -> Vec<DPrimeRingElement> {
    let mut row = Vec::with_capacity(dim);
    let mut power = ell.clone();
    row.push(ell.clone());
    for _ in 1..dim {
        power = power * *ell;
        row.push(power.clone());
    }
    row
}


pub fn flat_vdf(challenge: &DPrimeRingElement, a: &Vec<Vec<DPrimeRingElement>>, time: usize) -> (Vec<DPrimeRingElement>, Vec<DPrimeRingElement>, Vec<DPrimeRingElement>) {
    let mut squeeze_vector  = powers(&challenge, MODULE_SIZE);
    let mut squeeze_vector_0  = squeeze_vector.clone();
    let G = tensor_identity_matrix_with_vector(&get_g(LOG_Q), MODULE_SIZE);

    let vec_1 = parallel_dot_vector_matrix(&squeeze_vector, &G);
    let power = squeeze_vector.last().unwrap().clone();

    let mut squeeze_vector_2 = vector_element_product(&squeeze_vector, &power);

    let vec_2 = parallel_dot_vector_matrix(&squeeze_vector_2, &a);
    let mut vec = add_vectors(&vec_1, &vec_2);
    let mut result = vec.clone();

    for _ in 1..time {
        vec = vector_element_product(&vec, &power);
        squeeze_vector_2 = vector_element_product(&squeeze_vector_2, &power);

        result.append(&mut vec.clone());
    }

    (result, squeeze_vector_0, squeeze_vector_2)
}

#[test]
fn test_vdf_chunks() {
    let time = 18;
    let chunks = 3;
    let chunk_size = time / chunks;
    let a = sample_random_mat(MODULE_SIZE, LOG_Q * MODULE_SIZE);
    let y_a = sample_random_vector(MODULE_SIZE);
    use std::time::Instant;
    let now = Instant::now();
    let output = execute_vdf(&y_a, &a, chunks, time);
    let elapsed = now.elapsed();
    println_with_timestamp!("Elapsed: {:.2?}", elapsed);

    // Reshape the witness
    let witness_reshaped = crate::arithmetic::reshape(&output.witness, LOG_Q * MODULE_SIZE);
    // Generate the G matrix
    let G = tensor_identity_matrix_with_vector(&get_g(LOG_Q), MODULE_SIZE);
    assert_eq!(parallel_dot_matrix_vector(&G, &witness_reshaped[0]), y_a );

    // Validate intermediate steps
    for i in 1..(time - 1) {
        assert_eq!(
            arithmetic::add(&parallel_dot_matrix_vector(&G, &witness_reshaped[i] )
                            , &parallel_dot_matrix_vector(&a, &witness_reshaped[i - 1] )),
            zero_vector(MODULE_SIZE) );
    }

    // Validate final output
    assert_eq!(parallel_dot_matrix_vector(&a, &witness_reshaped[time - 1]), output.output_image);

    // Reshape and flatten chunks
    let chunked_witness = reshape(&witness_reshaped, chunk_size);
    let chunked_witness_flattened: Vec<Vec<DPrimeRingElement>> = chunked_witness.iter().map(|chunk| { chunk.iter().flatten().cloned().collect()}).collect();

    // Generate the G and A tensors
    let G_tensor = vec![tensor_identity_matrix_with_matrix(&G, chunk_size), vec![zero_vector(MODULE_SIZE * LOG_Q * chunk_size); MODULE_SIZE]].concat();
    let A_tensor = vec![vec![zero_vector(MODULE_SIZE * LOG_Q * chunk_size); MODULE_SIZE], tensor_identity_matrix_with_matrix(&a, chunk_size)].concat();
    let GA_tensor = add_matrices(&G_tensor, &A_tensor);

    // Compute the expected image
    let ell = parallel_dot_matrix_matrix(&GA_tensor, &transpose(&chunked_witness_flattened));
    let negative_images: Vec<Vec<DPrimeRingElement>> = output.intermediate_images.iter().map(|image| { image.iter().map(DPrimeRingElement::negative).collect::<Vec<_>>() }).collect();
    let top_row = transpose(&vec![vec![y_a], output.intermediate_images].concat());
    let bottom_row = transpose(&vec![negative_images, vec![output.output_image]].concat());
    let challenge = Ring::random();
    let  (result, squeeze_vector_0, squeeze_vector) = flat_vdf(&challenge, &a, chunk_size);
    let r1 = parallel_dot_matrix_vector(&transpose(&top_row), &squeeze_vector_0);
    let r2 = parallel_dot_matrix_vector(&transpose(&bottom_row), &squeeze_vector);
    let r = add_vectors(&r1, &r2);
    let expected_image = vec![top_row, zero_mat((chunk_size - 1) * MODULE_SIZE, chunks), bottom_row].concat();

    assert_eq!(ell, expected_image);

    let l = parallel_dot_matrix_vector(&chunked_witness_flattened, &result);

    assert_eq!(l, r);
}
